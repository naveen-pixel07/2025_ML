{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRl3cnvlUzCO2jaCNK6r3t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveen-pixel07/2025_ML/blob/main/Bayesian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c1f67cb"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=5, n_informative=3, n_redundant=0, n_repeated=0, n_classes=3, n_clusters_per_class=1, weights=[0.5, 0.3, 0.2], flip_y=0.01, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2173ebbe"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "def calculate_prior(y_train):\n",
        "    classes, counts = np.unique(y_train, return_counts=True)\n",
        "    prior_prob = counts / len(y_train)\n",
        "    return dict(zip(classes, prior_prob))\n",
        "\n",
        "def calculate_likelihood(X_train, y_train, x):\n",
        "    classes = np.unique(y_train)\n",
        "    likelihoods = {}\n",
        "    for c in classes:\n",
        "        X_c = X_train[y_train == c]\n",
        "        mean_c = np.mean(X_c, axis=0)\n",
        "        covariance_c = np.cov(X_c.T) + np.eye(X_c.shape[1]) * 1e-6\n",
        "        likelihoods[c] = multivariate_normal.pdf(x, mean=mean_c, cov=covariance_c)\n",
        "    return likelihoods\n",
        "\n",
        "def calculate_posterior(prior_prob, likelihoods):\n",
        "    posterior = {}\n",
        "    evidence = sum(prior_prob[c] * likelihoods[c] for c in prior_prob)\n",
        "    for c in prior_prob:\n",
        "        posterior[c] = (prior_prob[c] * likelihoods[c]) / (evidence if evidence != 0 else 1e-9)\n",
        "    return posterior\n",
        "\n",
        "def classify(X_train, y_train, x):\n",
        "    prior_prob = calculate_prior(y_train)\n",
        "    likelihoods = calculate_likelihood(X_train, y_train, x)\n",
        "    posterior = calculate_posterior(prior_prob, likelihoods)\n",
        "    return max(posterior, key=posterior.get)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95da0583",
        "outputId": "47ab705b-b301-4a76-cdc1-7a661fc4ad71"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "for test_point in X_test:\n",
        "    predicted_class = classify(X_train, y_train, test_point)\n",
        "    predicted_labels.append(predicted_class)\n",
        "\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "accuracy = accuracy_score(y_test, predicted_labels)\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "weighted_precision = precision_score(y_test, predicted_labels, average='weighted')\n",
        "weighted_recall = recall_score(y_test, predicted_labels, average='weighted')\n",
        "weighted_f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Overall Precision (weighted): {weighted_precision:.4f}\")\n",
        "print(f\"Overall Recall (weighted): {weighted_recall:.4f}\")\n",
        "print(f\"Overall F1-Score (weighted): {weighted_f1:.4f}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 0.9500\n",
            "Overall Precision (weighted): 0.9509\n",
            "Overall Recall (weighted): 0.9500\n",
            "Overall F1-Score (weighted): 0.9500\n"
          ]
        }
      ]
    }
  ]
}